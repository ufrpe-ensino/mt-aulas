{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLsDqQxqYTWi"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufrpe-ensino/mt-aulas/blob/master/03a_Classifica%C3%A7%C3%A3oTextos_Spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "# Classificação de texto: supervisionado\n",
        "\n",
        "A classificação de texto é uma tarefa de aprendizado de máquina que consiste em categorizar textos em classes predefinidas. Na abordagem **supervisionada**, o modelo é treinado com um conjunto de dados rotulados, onde cada texto já possui uma classe associada. Essa abordagem requer uma quantidade significativa de dados rotulados para alcançar bons resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bibliotecas: Spacy e XGBoost\n",
        "\n",
        "Neste notebook, utilizaremos a biblioteca SPACY (https://spacy.io/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfkRRYHjY9td"
      },
      "source": [
        "# Carregando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "-X4g3K1-UlcW",
        "outputId": "571821ef-291d-48b6-8204-4b4883c44914"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ufrpe-ensino/mt-aulas/refs/heads/master/data/spam_classification/spam.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "vvt3c6i9LF1j",
        "outputId": "efa9008f-4ae6-4f86-ff78-97d6e25e1ef9"
      },
      "outputs": [],
      "source": [
        "df.isnull().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Abordagem Supervisionada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_-yPkfkZAmr"
      },
      "source": [
        "## Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28n3blcWZC95"
      },
      "source": [
        "Remoção de pontuação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC-a8vReVU70"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "df['Text_no_punctuation_number'] = df['Text'].apply(lambda x: [token for token in x if token not in string.punctuation and not token.isnumeric()])\n",
        "df['Text_no_punctuation_number'] = df['Text_no_punctuation_number'].apply(lambda x: ''.join(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO673DrZZF9S"
      },
      "source": [
        "Remoção de stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKqq08LkczeD"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "df['Text_no_stopword'] = df['Text_no_punctuation_number'].apply(lambda x: [token.text.lower() for token in nlp(x) if (token.is_stop == False and len(token.text)>3)])\n",
        "df['Text_no_stopword'] = df['Text_no_stopword'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NASi7A7UZJqG"
      },
      "source": [
        "Lematização e remoção de stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxCD38dwQ10g"
      },
      "outputs": [],
      "source": [
        "df['Text_lemma_no_stopword'] = df['Text_no_stopword'].apply(lambda x: [token.lemma_ for token in nlp(x)])\n",
        "df['Text_lemma_no_stopword'] = df['Text_lemma_no_stopword'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEngG5j_ZNEN"
      },
      "source": [
        "Lematização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7A2BmjxRLiD"
      },
      "outputs": [],
      "source": [
        "df['Text_lemma'] = df['Text_no_punctuation_number'].apply(lambda x: [token.lemma_ for token in nlp(x)])\n",
        "df['Text_lemma'] = df['Text_lemma'].apply(lambda x: ' '.join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "BIw4Wb4kbv_H",
        "outputId": "4515b980-bdf0-4657-becd-d3b4c4f1cfa2"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR8ii48AZQid"
      },
      "source": [
        "Extração de features usando o TfidfVectorizer - neste exemplo iremos avaliar os textos com lemma e sem stopword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AosXl0EhVOuJ",
        "outputId": "376e1787-8c0c-4fca-a08a-04a033ac674f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Código para pegar os valores de uma coluna do dataframe (dataframe,nomedacoluna,.values)\n",
        "X = df.Text_lemma_no_stopword.values\n",
        "\n",
        "#Extração das features\n",
        "vectorizer = TfidfVectorizer(use_idf=True)\n",
        "tfidf_model = vectorizer.fit(X)\n",
        "\n",
        "X_tfidf = tfidf_model.transform(X)\n",
        "\n",
        "print(X_tfidf[0,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRriAUaDZq97"
      },
      "source": [
        "## Função para treinamento e avaliação de vários modelos e métricas ao mesmo tempo usando treinamento e teste. Explicações dentro da função."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHy4D2kMaULb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, make_scorer\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def run_exps_train_test(x_train: pd.DataFrame ,\n",
        "             y_train: pd.DataFrame,\n",
        "             x_test:  pd.DataFrame,\n",
        "             y_test:  pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Lightweight script to test many models and find winners\n",
        "    :param x_train: train split\n",
        "    :param y_train: training target vector\n",
        "    :param x_test: test split\n",
        "    :param y_test: test target vector\n",
        "    :return: DataFrame of predictions\n",
        "    \"\"\"\n",
        "\n",
        "    dfs = []\n",
        "    \n",
        "    #Modelos que serão avaliados (podem incluir quantos modelos quiserem)\n",
        "    models = [\n",
        "          ('LogReg', LogisticRegression()),\n",
        "          ('RF', RandomForestClassifier()),\n",
        "          ('KNN', KNeighborsClassifier()),\n",
        "          ('SVM', SVC(kernel=\"linear\")),\n",
        "          ('MNB', MultinomialNB()),\n",
        "          ('Adaboost', AdaBoostClassifier()),\n",
        "          ('XGB', XGBClassifier())\n",
        "        ]\n",
        "\n",
        "    results = []\n",
        "    names = []\n",
        "    #Métricas que serão avaliadas (podem incluir quantos métricas quiserem)\n",
        "    kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "    scoring = {\n",
        "                'accuracy': 'accuracy',\n",
        "                'precision_weighted': 'precision_weighted',\n",
        "                'recall_weighted': 'recall_weighted',\n",
        "                'f1_weighted': 'f1_weighted',\n",
        "                'kappa' : kappa_scorer\n",
        "                }\n",
        "\n",
        "   #Nomes das classes, esse atributo é opcional, caso não seja incluido o modelo\n",
        "   #vai apresentar os valores de 0-n onde n é o número de classes.\n",
        "   # target_names = ['ham', 'spam']\n",
        "\n",
        "    for name, model in models:\n",
        "        #em alguns casos é interessante se criar um classificador para cada classe\n",
        "        #caso seja o caso descomentar linha abaixo\n",
        "        #model = OneVsRestClassifier(model)\n",
        "    \n",
        "        if name == 'XGB':\n",
        "            # XGBoost nao aceita classes como string\n",
        "            y_train = [1 if x == 'spam' else 0 for x in y_train]\n",
        "            y_test  = [1 if x == 'spam' else 0 for x in y_test]\n",
        "            \n",
        "        clf = model.fit(x_train, y_train)\n",
        "        y_pred = clf.predict(x_test)\n",
        "        print(name)\n",
        "        print(classification_report(y_test, y_pred))\n",
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F1yx4mAaSrg"
      },
      "source": [
        "## Recuperando classes das instâncias de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrNnZzDkWShP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Y = df.Class.values\n",
        "tfidf_train, tfidf_test, class_train, class_test = train_test_split(\n",
        "    X_tfidf, Y, test_size=0.25, stratify=Y\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxYW56ozabB7"
      },
      "source": [
        "## Rodar função para treinamento e avaliação descrita acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T4mVuHiiWbK_",
        "outputId": "e9722a4e-9fae-4b59-fffe-84b08f8dea0b"
      },
      "outputs": [],
      "source": [
        "run_exps_train_test(tfidf_train, class_train, tfidf_test, class_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O5J-JrkWyUw"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "def run_exps_crossvalidation(x: pd.DataFrame ,\n",
        "             y: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Lightweight script to test many models and find winners\n",
        "    :param x: values vector\n",
        "    :param y: target vector\n",
        "    :return: DataFrame of predictions\n",
        "    \"\"\"\n",
        "\n",
        "    dfs = []\n",
        "    print(\"CARREGANDO MODELO\")\n",
        "    models = [\n",
        "          ('LogReg', LogisticRegression()),\n",
        "          ('RF', RandomForestClassifier()),\n",
        "          ('KNN', KNeighborsClassifier()),\n",
        "          ('MNB', MultinomialNB()),\n",
        "          ('Adaboost', AdaBoostClassifier()),\n",
        "          ('XGB', XGBClassifier())\n",
        "        ]\n",
        "\n",
        "    results = []\n",
        "    names = []\n",
        "    kappa_scorer = make_scorer(cohen_kappa_score)\n",
        "    scoring = {\n",
        "                'accuracy': 'accuracy',\n",
        "                'precision_weighted': 'precision_weighted',\n",
        "                'recall_weighted': 'recall_weighted',\n",
        "                'f1_weighted': 'f1_weighted',\n",
        "                'kappa' : kappa_scorer\n",
        "                }\n",
        "    print(\"RODANDO\")\n",
        "    for name, model in models:\n",
        "        print(name)\n",
        "\n",
        "        kfold = model_selection.KFold(n_splits=10, shuffle=True)\n",
        "        if name == 'XGB':\n",
        "            # XGBoost nao aceita classes como string\n",
        "            y = [1 if x == 'spam' else 0 for x in y]\n",
        "        cv_results = model_selection.cross_validate(model, x, y, cv=kfold, scoring=scoring)\n",
        "        results.append(cv_results)\n",
        "        names.append(name)\n",
        "        this_df = pd.DataFrame(cv_results)\n",
        "        this_df['model'] = name\n",
        "        dfs.append(this_df)\n",
        "\n",
        "    final = pd.concat(dfs, ignore_index=True)\n",
        "    return final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XbApXQvFXWqg",
        "outputId": "e1ee0a00-b24d-4808-8246-b6c2fdaabbc1"
      },
      "outputs": [],
      "source": [
        "final = run_exps_crossvalidation(X_tfidf, Y)\n",
        "final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "nMDR4IYBXXDw",
        "outputId": "9f3ca327-e455-46a1-8055-f54c0c44274b"
      },
      "outputs": [],
      "source": [
        "grouped = final[['test_accuracy','test_f1_weighted', 'test_kappa']].groupby(final['model'])\n",
        "grouped.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "Qg5w4vXkjfXa",
        "outputId": "bb33378d-4fc2-4492-ec6d-80f11dc4b56a"
      },
      "outputs": [],
      "source": [
        "grouped.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkINnuncmwxJ"
      },
      "source": [
        "## Medindo a importância das features no classificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TUKvdPEm3X0"
      },
      "source": [
        "Treinar o modelo de RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPPtFJqhkkun",
        "outputId": "11f15d6e-fe23-4eba-c9bb-013493e28748"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier()\n",
        "model.fit(X_tfidf, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTOdGOGNm8RG"
      },
      "source": [
        "Extraindo a importância das características"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JllrWBDCnBSa",
        "outputId": "a2262b27-e74a-4fa0-9bec-40fe8cac887c"
      },
      "outputs": [],
      "source": [
        "mdg_features = model.feature_importances_\n",
        "mdg_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfDV-oUynGtB"
      },
      "source": [
        "Nomes e índices das features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJc0XyFVk6y3"
      },
      "outputs": [],
      "source": [
        "features_names = tfidf_model.get_feature_names_out()\n",
        "\n",
        "feature_importance = pd.DataFrame(mdg_features,\n",
        "                                   index = features_names,\n",
        "                                   columns=['importance']).sort_values('importance',ascending=False)\n",
        "\n",
        "index_feature_importance = pd.DataFrame(mdg_features,\n",
        "                                   index = range(len(features_names)),\n",
        "                                   columns=['importance']).sort_values('importance',ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01AIyn6lnT-U"
      },
      "source": [
        "Montar o array de importância"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "sCbeqlKNk8et",
        "outputId": "c938e98e-1d1d-4c45-b4e8-247b8eb8da12"
      },
      "outputs": [],
      "source": [
        "labels_features = feature_importance['importance'].index[:30]\n",
        "indices_features = index_feature_importance['importance'].index[:30]\n",
        "mdg_features = feature_importance['importance'].values[:30]\n",
        "\n",
        "data = {\"Variable\": labels_features, \"MDG\": mdg_features}\n",
        "\n",
        "df_feature_importance = pd.DataFrame(data)\n",
        "df_feature_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "teaching",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
